// Code generated by tygo. DO NOT EDIT.

import type { Duration } from "./caddy-core";

//////////
// source: addresses.go

//////////
// source: admin.go

//////////
// source: caddyfile.go

//////////
// source: copyresponse.go

/**
 * CopyResponseHandler is a special HTTP handler which may
 * only be used within reverse_proxy's handle_response routes,
 * to copy the proxy response. EXPERIMENTAL, subject to change.
 */
export interface CopyResponseHandler {
  /**
   * To write the upstream response's body but with a different
   * status code, set this field to the desired status code.
   */
  status_code?: any /* caddyhttp.WeakString */;
}
/**
 * CopyResponseHeadersHandler is a special HTTP handler which may
 * only be used within reverse_proxy's handle_response routes,
 * to copy headers from the proxy response. EXPERIMENTAL;
 * subject to change.
 */
export interface CopyResponseHeadersHandler {
  /**
   * A list of header fields to copy from the response.
   * Cannot be defined at the same time as Exclude.
   */
  include?: string[];
  /**
   * A list of header fields to skip copying from the response.
   * Cannot be defined at the same time as Include.
   */
  exclude?: string[];
}

//////////
// source: healthchecks.go

/**
 * HealthChecks configures active and passive health checks.
 */
export interface HealthChecks {
  /**
   * Active health checks run in the background on a timer. To
   * minimally enable active health checks, set either path or
   * port (or both). Note that active health check status
   * (healthy/unhealthy) is stored per-proxy-handler, not
   * globally; this allows different handlers to use different
   * criteria to decide what defines a healthy backend.
   * Active health checks do not run for dynamic upstreams.
   */
  active?: ActiveHealthChecks;
  /**
   * Passive health checks monitor proxied requests for errors or timeouts.
   * To minimally enable passive health checks, specify at least an empty
   * config object with fail_duration > 0. Passive health check state is
   * shared (stored globally), so a failure from one handler will be counted
   * by all handlers; but the tolerances or standards for what defines
   * healthy/unhealthy backends is configured per-proxy-handler.
   * Passive health checks technically do operate on dynamic upstreams,
   * but are only effective for very busy proxies where the list of
   * upstreams is mostly stable. This is because the shared/global
   * state of upstreams is cleaned up when the upstreams are no longer
   * used. Since dynamic upstreams are allocated dynamically at each
   * request (specifically, each iteration of the proxy loop per request),
   * they are also cleaned up after every request. Thus, if there is a
   * moment when no requests are actively referring to a particular
   * upstream host, the passive health check state will be reset because
   * it will be garbage-collected. It is usually better for the dynamic
   * upstream module to only return healthy, available backends instead.
   */
  passive?: PassiveHealthChecks;
}
/**
 * ActiveHealthChecks holds configuration related to active
 * health checks (that is, health checks which occur in a
 * background goroutine independently).
 */
export interface ActiveHealthChecks {
  /**
   * Deprecated: Use 'uri' instead. This field will be removed. TODO: remove this field
   */
  path?: string;
  /**
   * The URI (path and query) to use for health checks
   */
  uri?: string;
  /**
   * The host:port to use (if different from the upstream's dial address)
   * for health checks. This should be used in tandem with `health_header` and
   * `{http.reverse_proxy.active.target_upstream}`. This can be helpful when
   * creating an intermediate service to do a more thorough health check.
   * If upstream is set, the active health check port is ignored.
   */
  upstream?: string;
  /**
   * The port to use (if different from the upstream's dial
   * address) for health checks. If active upstream is set,
   * this value is ignored.
   */
  port?: number /* int */;
  /**
   * HTTP headers to set on health check requests.
   */
  headers?: any /* http.Header */;
  /**
   * The HTTP method to use for health checks (default "GET").
   */
  method?: string;
  /**
   * The body to send with the health check request.
   */
  body?: string;
  /**
   * Whether to follow HTTP redirects in response to active health checks (default off).
   */
  follow_redirects?: boolean;
  /**
   * How frequently to perform active health checks (default 30s).
   */
  interval?: Duration;
  /**
   * How long to wait for a response from a backend before
   * considering it unhealthy (default 5s).
   */
  timeout?: Duration;
  /**
   * Number of consecutive health check passes before marking
   * a previously unhealthy backend as healthy again (default 1).
   */
  passes?: number /* int */;
  /**
   * Number of consecutive health check failures before marking
   * a previously healthy backend as unhealthy (default 1).
   */
  fails?: number /* int */;
  /**
   * The maximum response body to download from the backend
   * during a health check.
   */
  max_size?: number /* int64 */;
  /**
   * The HTTP status code to expect from a healthy backend.
   */
  expect_status?: number /* int */;
  /**
   * A regular expression against which to match the response
   * body of a healthy backend.
   */
  expect_body?: string;
}
/**
 * PassiveHealthChecks holds configuration related to passive
 * health checks (that is, health checks which occur during
 * the normal flow of request proxying).
 */
export interface PassiveHealthChecks {
  /**
   * How long to remember a failed request to a backend. A duration > 0
   * enables passive health checking. Default is 0.
   */
  fail_duration?: Duration;
  /**
   * The number of failed requests within the FailDuration window to
   * consider a backend as "down". Must be >= 1; default is 1. Requires
   * that FailDuration be > 0.
   */
  max_fails?: number /* int */;
  /**
   * Limits the number of simultaneous requests to a backend by
   * marking the backend as "down" if it has this many concurrent
   * requests or more.
   */
  unhealthy_request_count?: number /* int */;
  /**
   * Count the request as failed if the response comes back with
   * one of these status codes.
   */
  unhealthy_status?: number /* int */[];
  /**
   * Count the request as failed if the response takes at least this
   * long to receive.
   */
  unhealthy_latency?: Duration;
}
/**
 * CircuitBreaker is a type that can act as an early-warning
 * system for the health checker when backends are getting
 * overloaded. This interface is still experimental and is
 * subject to change.
 */
export type CircuitBreaker = any;

//////////
// source: hosts.go

/**
 * UpstreamPool is a collection of upstreams.
 */
export type UpstreamPool = (Upstream | undefined)[];
/**
 * Upstream bridges this proxy's configuration to the
 * state of the backend host it is correlated with.
 * Upstream values must not be copied.
 */
export interface Upstream {
  /**
   * The [network address](/docs/conventions#network-addresses)
   * to dial to connect to the upstream. Must represent precisely
   * one socket (i.e. no port ranges). A valid network address
   * either has a host and port or is a unix socket address.
   * Placeholders may be used to make the upstream dynamic, but be
   * aware of the health check implications of this: a single
   * upstream that represents numerous (perhaps arbitrary) backends
   * can be considered down if one or enough of the arbitrary
   * backends is down. Also be aware of open proxy vulnerabilities.
   */
  dial?: string;
  /**
   * The maximum number of simultaneous requests to allow to
   * this upstream. If set, overrides the global passive health
   * check UnhealthyRequestCount value.
   */
  max_requests?: number /* int */;
}
/**
 * Host is the basic, in-memory representation of the state of a remote host.
 * Its fields are accessed atomically and Host values must not be copied.
 */
export interface Host {}
/**
 * DialInfo contains information needed to dial a
 * connection to an upstream host. This information
 * may be different than that which is represented
 * in a URL (for example, unix sockets don't have
 * a host that can be represented in a URL, but
 * they certainly have a network name and address).
 */
export interface DialInfo {
  /**
   * Upstream is the Upstream associated with
   * this DialInfo. It may be nil.
   */
  Upstream?: Upstream;
  /**
   * The network to use. This should be one of
   * the values that is accepted by net.Dial:
   * https://golang.org/pkg/net/#Dial
   */
  Network: string;
  /**
   * The address to dial. Follows the same
   * semantics and rules as net.Dial.
   */
  Address: string;
  /**
   * Host and Port are components of Address.
   */
  Host: string;
  /**
   * Host and Port are components of Address.
   */
  Port: string;
}
/**
 * ProxyProtocolInfo contains information needed to write proxy protocol to a
 * connection to an upstream host.
 */
export interface ProxyProtocolInfo {
  AddrPort: any /* netip.AddrPort */;
}

//////////
// source: httptransport.go

/**
 * HTTPTransport is essentially a configuration wrapper for http.Transport.
 * It defines a JSON structure useful when configuring the HTTP transport
 * for Caddy's reverse proxy. It builds its http.Transport at Provision.
 */
export interface HTTPTransport {
  /**
   * Configures the DNS resolver used to resolve the IP address of upstream hostnames.
   */
  resolver?: UpstreamResolver;
  /**
   * Configures TLS to the upstream. Setting this to an empty struct
   * is sufficient to enable TLS with reasonable defaults.
   */
  tls?: TLSConfig;
  /**
   * Configures HTTP Keep-Alive (enabled by default). Should only be
   * necessary if rigorous testing has shown that tuning this helps
   * improve performance.
   */
  keep_alive?: KeepAlive;
  /**
   * Whether to enable compression to upstream. Default: true
   */
  compression?: boolean;
  /**
   * Maximum number of connections per host. Default: 0 (no limit)
   */
  max_conns_per_host?: number /* int */;
  /**
   * If non-empty, which PROXY protocol version to send when
   * connecting to an upstream. Default: off.
   */
  proxy_protocol?: string;
  /**
   * URL to the server that the HTTP transport will use to proxy
   * requests to the upstream. See http.Transport.Proxy for
   * information regarding supported protocols. This value takes
   * precedence over `HTTP_PROXY`, etc.
   * Providing a value to this parameter results in
   * requests flowing through the reverse_proxy in the following
   * way:
   * User Agent ->
   *  reverse_proxy ->
   *  forward_proxy_url -> upstream
   * Default: http.ProxyFromEnvironment
   * DEPRECATED: Use NetworkProxyRaw|`network_proxy` instead. Subject to removal.
   */
  forward_proxy_url?: string;
  /**
   * How long to wait before timing out trying to connect to
   * an upstream. Default: `3s`.
   */
  dial_timeout?: Duration;
  /**
   * How long to wait before spawning an RFC 6555 Fast Fallback
   * connection. A negative value disables this. Default: `300ms`.
   */
  dial_fallback_delay?: Duration;
  /**
   * How long to wait for reading response headers from server. Default: No timeout.
   */
  response_header_timeout?: Duration;
  /**
   * The length of time to wait for a server's first response
   * headers after fully writing the request headers if the
   * request has a header "Expect: 100-continue". Default: No timeout.
   */
  expect_continue_timeout?: Duration;
  /**
   * The maximum bytes to read from response headers. Default: `10MiB`.
   */
  max_response_header_size?: number /* int64 */;
  /**
   * The size of the write buffer in bytes. Default: `4KiB`.
   */
  write_buffer_size?: number /* int */;
  /**
   * The size of the read buffer in bytes. Default: `4KiB`.
   */
  read_buffer_size?: number /* int */;
  /**
   * The maximum time to wait for next read from backend. Default: no timeout.
   */
  read_timeout?: Duration;
  /**
   * The maximum time to wait for next write to backend. Default: no timeout.
   */
  write_timeout?: Duration;
  /**
   * The versions of HTTP to support. As a special case, "h2c"
   * can be specified to use H2C (HTTP/2 over Cleartext) to the
   * upstream (this feature is experimental and subject to
   * change or removal). Default: ["1.1", "2"]
   * EXPERIMENTAL: "3" enables HTTP/3, but it must be the only
   * version specified if enabled. Additionally, HTTPS must be
   * enabled to the upstream as HTTP/3 requires TLS. Subject
   * to change or removal while experimental.
   */
  versions?: string[];
  /**
   * Specify the address to bind to when connecting to an upstream. In other words,
   * it is the address the upstream sees as the remote address.
   */
  local_address?: string;
  /**
   * The module that provides the network (forward) proxy
   * URL that the HTTP transport will use to proxy
   * requests to the upstream. See [http.Transport.Proxy](https://pkg.go.dev/net/http#Transport.Proxy)
   * for information regarding supported protocols.
   * Providing a value to this parameter results in requests
   * flowing through the reverse_proxy in the following way:
   * User Agent ->
   *  reverse_proxy ->
   *  [proxy provided by the module] -> upstream
   * If nil, defaults to reading the `HTTP_PROXY`,
   * `HTTPS_PROXY`, and `NO_PROXY` environment variables.
   */
  network_proxy?: unknown;
}
/**
 * TLSConfig holds configuration related to the TLS configuration for the
 * transport/client.
 */
export interface TLSConfig {
  /**
   * Certificate authority module which provides the certificate pool of trusted certificates
   */
  ca?: unknown;
  /**
   * Deprecated: Use the `ca` field with the `tls.ca_pool.source.inline` module instead.
   * Optional list of base64-encoded DER-encoded CA certificates to trust.
   */
  root_ca_pool?: string[];
  /**
   * Deprecated: Use the `ca` field with the `tls.ca_pool.source.file` module instead.
   * List of PEM-encoded CA certificate files to add to the same trust
   * store as RootCAPool (or root_ca_pool in the JSON).
   */
  root_ca_pem_files?: string[];
  /**
   * PEM-encoded client certificate filename to present to servers.
   */
  client_certificate_file?: string;
  /**
   * PEM-encoded key to use with the client certificate.
   */
  client_certificate_key_file?: string;
  /**
   * If specified, Caddy will use and automate a client certificate
   * with this subject name.
   */
  client_certificate_automate?: string;
  /**
   * If true, TLS verification of server certificates will be disabled.
   * This is insecure and may be removed in the future. Do not use this
   * option except in testing or local development environments.
   */
  insecure_skip_verify?: boolean;
  /**
   * The duration to allow a TLS handshake to a server. Default: No timeout.
   */
  handshake_timeout?: Duration;
  /**
   * The server name used when verifying the certificate received in the TLS
   * handshake. By default, this will use the upstream address' host part.
   * You only need to override this if your upstream address does not match the
   * certificate the upstream is likely to use. For example if the upstream
   * address is an IP address, then you would need to configure this to the
   * hostname being served by the upstream server. Currently, this does not
   * support placeholders because the TLS config is not provisioned on each
   * connection, so a static value must be used.
   */
  server_name?: string;
  /**
   * TLS renegotiation level. TLS renegotiation is the act of performing
   * subsequent handshakes on a connection after the first.
   * The level can be:
   *  - "never": (the default) disables renegotiation.
   *  - "once": allows a remote server to request renegotiation once per connection.
   *  - "freely": allows a remote server to repeatedly request renegotiation.
   */
  renegotiation?: string;
  /**
   * Skip TLS ports specifies a list of upstream ports on which TLS should not be
   * attempted even if it is configured. Handy when using dynamic upstreams that
   * return HTTP and HTTPS endpoints too.
   * When specified, TLS will automatically be configured on the transport.
   * The value can be a list of any valid tcp port numbers, default empty.
   */
  except_ports?: string[];
  /**
   * The list of elliptic curves to support. Caddy's
   * defaults are modern and secure.
   */
  curves?: string[];
}
/**
 * KeepAlive holds configuration pertaining to HTTP Keep-Alive.
 */
export interface KeepAlive {
  /**
   * Whether HTTP Keep-Alive is enabled. Default: `true`
   */
  enabled?: boolean;
  /**
   * How often to probe for liveness. Default: `30s`.
   */
  probe_interval?: Duration;
  /**
   * Maximum number of idle connections. Default: `0`, which means no limit.
   */
  max_idle_conns?: number /* int */;
  /**
   * Maximum number of idle connections per host. Default: `32`.
   */
  max_idle_conns_per_host?: number /* int */;
  /**
   * How long connections should be kept alive when idle. Default: `2m`.
   */
  idle_timeout?: Duration;
}

//////////
// source: metrics.go

//////////
// source: reverseproxy.go

/**
 * Handler implements a highly configurable and production-ready reverse proxy.
 * Upon proxying, this module sets the following placeholders (which can be used
 * both within and after this handler; for example, in response headers):
 * Placeholder | Description
 * ------------|-------------
 * `{http.reverse_proxy.upstream.address}` | The full address to the upstream as given in the config
 * `{http.reverse_proxy.upstream.hostport}` | The host:port of the upstream
 * `{http.reverse_proxy.upstream.host}` | The host of the upstream
 * `{http.reverse_proxy.upstream.port}` | The port of the upstream
 * `{http.reverse_proxy.upstream.requests}` | The approximate current number of requests to the upstream
 * `{http.reverse_proxy.upstream.max_requests}` | The maximum approximate number of requests allowed to the upstream
 * `{http.reverse_proxy.upstream.fails}` | The number of recent failed requests to the upstream
 * `{http.reverse_proxy.upstream.latency}` | How long it took the proxy upstream to write the response header.
 * `{http.reverse_proxy.upstream.latency_ms}` | Same as 'latency', but in milliseconds.
 * `{http.reverse_proxy.upstream.duration}` | Time spent proxying to the upstream, including writing response body to client.
 * `{http.reverse_proxy.upstream.duration_ms}` | Same as 'upstream.duration', but in milliseconds.
 * `{http.reverse_proxy.duration}` | Total time spent proxying, including selecting an upstream, retries, and writing response.
 * `{http.reverse_proxy.duration_ms}` | Same as 'duration', but in milliseconds.
 * `{http.reverse_proxy.retries}` | The number of retries actually performed to communicate with an upstream.
 */
export interface Handler {
  /**
   * Configures the method of transport for the proxy. A transport
   * is what performs the actual "round trip" to the backend.
   * The default transport is plaintext HTTP.
   */
  transport?: unknown;
  /**
   * A circuit breaker may be used to relieve pressure on a backend
   * that is beginning to exhibit symptoms of stress or latency.
   * By default, there is no circuit breaker.
   */
  circuit_breaker?: unknown;
  /**
   * Load balancing distributes load/requests between backends.
   */
  load_balancing?: LoadBalancing;
  /**
   * Health checks update the status of backends, whether they are
   * up or down. Down backends will not be proxied to.
   */
  health_checks?: HealthChecks;
  /**
   * Upstreams is the static list of backends to proxy to.
   */
  upstreams?: UpstreamPool;
  /**
   * A module for retrieving the list of upstreams dynamically. Dynamic
   * upstreams are retrieved at every iteration of the proxy loop for
   * each request (i.e. before every proxy attempt within every request).
   * Active health checks do not work on dynamic upstreams, and passive
   * health checks are only effective on dynamic upstreams if the proxy
   * server is busy enough that concurrent requests to the same backends
   * are continuous. Instead of health checks for dynamic upstreams, it
   * is recommended that the dynamic upstream module only return available
   * backends in the first place.
   */
  dynamic_upstreams?: unknown;
  /**
   * Adjusts how often to flush the response buffer. By default,
   * no periodic flushing is done. A negative value disables
   * response buffering, and flushes immediately after each
   * write to the client. This option is ignored when the upstream's
   * response is recognized as a streaming response, or if its
   * content length is -1; for such responses, writes are flushed
   * to the client immediately.
   */
  flush_interval?: Duration;
  /**
   * A list of IP ranges (supports CIDR notation) from which
   * X-Forwarded-* header values should be trusted. By default,
   * no proxies are trusted, so existing values will be ignored
   * when setting these headers. If the proxy is trusted, then
   * existing values will be used when constructing the final
   * header values.
   */
  trusted_proxies?: string[];
  /**
   * Headers manipulates headers between Caddy and the backend.
   * By default, all headers are passed-thru without changes,
   * with the exceptions of special hop-by-hop headers.
   * X-Forwarded-For, X-Forwarded-Proto and X-Forwarded-Host
   * are also set implicitly.
   */
  headers?: any /* headers.Handler */;
  /**
   * If nonzero, the entire request body up to this size will be read
   * and buffered in memory before being proxied to the backend. This
   * should be avoided if at all possible for performance reasons, but
   * could be useful if the backend is intolerant of read latency or
   * chunked encodings.
   */
  request_buffers?: number /* int64 */;
  /**
   * If nonzero, the entire response body up to this size will be read
   * and buffered in memory before being proxied to the client. This
   * should be avoided if at all possible for performance reasons, but
   * could be useful if the backend has tighter memory constraints.
   */
  response_buffers?: number /* int64 */;
  /**
   * If nonzero, streaming requests such as WebSockets will be
   * forcibly closed at the end of the timeout. Default: no timeout.
   */
  stream_timeout?: Duration;
  /**
   * If nonzero, streaming requests such as WebSockets will not be
   * closed when the proxy config is unloaded, and instead the stream
   * will remain open until the delay is complete. In other words,
   * enabling this prevents streams from closing when Caddy's config
   * is reloaded. Enabling this may be a good idea to avoid a thundering
   * herd of reconnecting clients which had their connections closed
   * by the previous config closing. Default: no delay.
   */
  stream_close_delay?: Duration;
  /**
   * If configured, rewrites the copy of the upstream request.
   * Allows changing the request method and URI (path and query).
   * Since the rewrite is applied to the copy, it does not persist
   * past the reverse proxy handler.
   * If the method is changed to `GET` or `HEAD`, the request body
   * will not be copied to the backend. This allows a later request
   * handler -- either in a `handle_response` route, or after -- to
   * read the body.
   * By default, no rewrite is performed, and the method and URI
   * from the incoming request is used as-is for proxying.
   */
  rewrite?: any /* rewrite.Rewrite */;
  /**
   * List of handlers and their associated matchers to evaluate
   * after successful roundtrips. The first handler that matches
   * the response from a backend will be invoked. The response
   * body from the backend will not be written to the client;
   * it is up to the handler to finish handling the response.
   * If passive health checks are enabled, any errors from the
   * handler chain will not affect the health status of the
   * backend.
   * Three new placeholders are available in this handler chain:
   * - `{http.reverse_proxy.status_code}` The status code from the response
   * - `{http.reverse_proxy.status_text}` The status text from the response
   * - `{http.reverse_proxy.header.*}` The headers from the response
   */
  handle_response?: any /* caddyhttp.ResponseHandler */[];
  /**
   * If set, the proxy will write very detailed logs about its
   * inner workings. Enable this only when debugging, as it
   * will produce a lot of output.
   * EXPERIMENTAL: This feature is subject to change or removal.
   */
  verbose_logs?: boolean;
}
/**
 * LoadBalancing has parameters related to load balancing.
 */
export interface LoadBalancing {
  /**
   * A selection policy is how to choose an available backend.
   * The default policy is random selection.
   */
  selection_policy?: unknown;
  /**
   * How many times to retry selecting available backends for each
   * request if the next available host is down. If try_duration is
   * also configured, then retries may stop early if the duration
   * is reached. By default, retries are disabled (zero).
   */
  retries?: number /* int */;
  /**
   * How long to try selecting available backends for each request
   * if the next available host is down. Clients will wait for up
   * to this long while the load balancer tries to find an available
   * upstream host. If retries is also configured, tries may stop
   * early if the maximum retries is reached. By default, retries
   * are disabled (zero duration).
   */
  try_duration?: Duration;
  /**
   * How long to wait between selecting the next host from the pool.
   * Default is 250ms if try_duration is enabled, otherwise zero. Only
   * relevant when a request to an upstream host fails. Be aware that
   * setting this to 0 with a non-zero try_duration can cause the CPU
   * to spin if all backends are down and latency is very low.
   */
  try_interval?: Duration;
  /**
   * A list of matcher sets that restricts with which requests retries are
   * allowed. A request must match any of the given matcher sets in order
   * to be retried if the connection to the upstream succeeded but the
   * subsequent round-trip failed. If the connection to the upstream failed,
   * a retry is always allowed. If unspecified, only GET requests will be
   * allowed to be retried. Note that a retry is done with the next available
   * host according to the load balancing policy.
   */
  retry_match?: any /* caddyhttp.RawMatcherSets */;
}
/**
 * Selector selects an available upstream from the pool.
 */
export type Selector = any;
/**
 * UpstreamSource gets the list of upstreams that can be used when
 * proxying a request. Returned upstreams will be load balanced and
 * health-checked. This should be a very fast function -- instant
 * if possible -- and the return value must be as stable as possible.
 * In other words, the list of upstreams should ideally not change much
 * across successive calls. If the list of upstreams changes or the
 * ordering is not stable, load balancing will suffer. This function
 * may be called during each retry, multiple times per request, and as
 * such, needs to be instantaneous. The returned slice will not be
 * modified.
 */
export type UpstreamSource = any;
/**
 * DialError is an error that specifically occurs
 * in a call to Dial or DialContext.
 */
export interface DialError {}
/**
 * TLSTransport is implemented by transports
 * that are capable of using TLS.
 */
export type TLSTransport = any;
/**
 * H2CTransport is implemented by transports
 * that are capable of using h2c.
 */
export type H2CTransport = any;
/**
 * ProxyProtocolTransport is implemented by transports
 * that are capable of using proxy protocol.
 */
export type ProxyProtocolTransport = any;
/**
 * HealthCheckSchemeOverriderTransport is implemented by transports
 * that can override the scheme used for health checks.
 */
export type HealthCheckSchemeOverriderTransport = any;
/**
 * BufferedTransport is implemented by transports
 * that needs to buffer requests and/or responses.
 */
export type BufferedTransport = any;

//////////
// source: selectionpolicies.go

/**
 * RandomSelection is a policy that selects
 * an available host at random.
 */
export interface RandomSelection {}
/**
 * WeightedRoundRobinSelection is a policy that selects
 * a host based on weighted round-robin ordering.
 */
export interface WeightedRoundRobinSelection {
  /**
   * The weight of each upstream in order,
   * corresponding with the list of upstreams configured.
   */
  weights?: number /* int */[];
}
/**
 * RandomChoiceSelection is a policy that selects
 * two or more available hosts at random, then
 * chooses the one with the least load.
 */
export interface RandomChoiceSelection {
  /**
   * The size of the sub-pool created from the larger upstream pool. The default value
   * is 2 and the maximum at selection time is the size of the upstream pool.
   */
  choose?: number /* int */;
}
/**
 * LeastConnSelection is a policy that selects the
 * host with the least active requests. If multiple
 * hosts have the same fewest number, one is chosen
 * randomly. The term "conn" or "connection" is used
 * in this policy name due to its similar meaning in
 * other software, but our load balancer actually
 * counts active requests rather than connections,
 * since these days requests are multiplexed onto
 * shared connections.
 */
export interface LeastConnSelection {}
/**
 * RoundRobinSelection is a policy that selects
 * a host based on round-robin ordering.
 */
export interface RoundRobinSelection {}
/**
 * FirstSelection is a policy that selects
 * the first available host.
 */
export interface FirstSelection {}
/**
 * IPHashSelection is a policy that selects a host
 * based on hashing the remote IP of the request.
 */
export interface IPHashSelection {}
/**
 * ClientIPHashSelection is a policy that selects a host
 * based on hashing the client IP of the request, as determined
 * by the HTTP app's trusted proxies settings.
 */
export interface ClientIPHashSelection {}
/**
 * URIHashSelection is a policy that selects a
 * host by hashing the request URI.
 */
export interface URIHashSelection {}
/**
 * QueryHashSelection is a policy that selects
 * a host based on a given request query parameter.
 */
export interface QueryHashSelection {
  /**
   * The query key whose value is to be hashed and used for upstream selection.
   */
  key?: string;
  /**
   * The fallback policy to use if the query key is not present. Defaults to `random`.
   */
  fallback?: unknown;
}
/**
 * HeaderHashSelection is a policy that selects
 * a host based on a given request header.
 */
export interface HeaderHashSelection {
  /**
   * The HTTP header field whose value is to be hashed and used for upstream selection.
   */
  field?: string;
  /**
   * The fallback policy to use if the header is not present. Defaults to `random`.
   */
  fallback?: unknown;
}
/**
 * CookieHashSelection is a policy that selects
 * a host based on a given cookie name.
 */
export interface CookieHashSelection {
  /**
   * The HTTP cookie name whose value is to be hashed and used for upstream selection.
   */
  name?: string;
  /**
   * Secret to hash (Hmac256) chosen upstream in cookie
   */
  secret?: string;
  /**
   * The cookie's Max-Age before it expires. Default is no expiry.
   */
  max_age?: Duration;
  /**
   * The fallback policy to use if the cookie is not present. Defaults to `random`.
   */
  fallback?: unknown;
}

//////////
// source: streaming.go

//////////
// source: upstreams.go

/**
 * SRVUpstreams provides upstreams from SRV lookups.
 * The lookup DNS name can be configured either by
 * its individual parts (that is, specifying the
 * service, protocol, and name separately) to form
 * the standard "_service._proto.name" domain, or
 * the domain can be specified directly in name by
 * leaving service and proto empty. See RFC 2782.
 * Lookups are cached and refreshed at the configured
 * refresh interval.
 * Returned upstreams are sorted by priority and weight.
 */
export interface SRVUpstreams {
  /**
   * The service label.
   */
  service?: string;
  /**
   * The protocol label; either tcp or udp.
   */
  proto?: string;
  /**
   * The name label; or, if service and proto are
   * empty, the entire domain name to look up.
   */
  name?: string;
  /**
   * The interval at which to refresh the SRV lookup.
   * Results are cached between lookups. Default: 1m
   */
  refresh?: Duration;
  /**
   * If > 0 and there is an error with the lookup,
   * continue to use the cached results for up to
   * this long before trying again, (even though they
   * are stale) instead of returning an error to the
   * client. Default: 0s.
   */
  grace_period?: Duration;
  /**
   * Configures the DNS resolver used to resolve the
   * SRV address to SRV records.
   */
  resolver?: UpstreamResolver;
  /**
   * If Resolver is configured, how long to wait before
   * timing out trying to connect to the DNS server.
   */
  dial_timeout?: Duration;
  /**
   * If Resolver is configured, how long to wait before
   * spawning an RFC 6555 Fast Fallback connection.
   * A negative value disables this.
   */
  dial_fallback_delay?: Duration;
}
export interface IPVersions {
  ipv4?: boolean;
  ipv6?: boolean;
}
/**
 * AUpstreams provides upstreams from A/AAAA lookups.
 * Results are cached and refreshed at the configured
 * refresh interval.
 */
export interface AUpstreams {
  /**
   * The domain name to look up.
   */
  name?: string;
  /**
   * The port to use with the upstreams. Default: 80
   */
  port?: string;
  /**
   * The interval at which to refresh the A lookup.
   * Results are cached between lookups. Default: 1m
   */
  refresh?: Duration;
  /**
   * Configures the DNS resolver used to resolve the
   * domain name to A records.
   */
  resolver?: UpstreamResolver;
  /**
   * If Resolver is configured, how long to wait before
   * timing out trying to connect to the DNS server.
   */
  dial_timeout?: Duration;
  /**
   * If Resolver is configured, how long to wait before
   * spawning an RFC 6555 Fast Fallback connection.
   * A negative value disables this.
   */
  dial_fallback_delay?: Duration;
  /**
   * The IP versions to resolve for. By default, both
   * "ipv4" and "ipv6" will be enabled, which
   * correspond to A and AAAA records respectively.
   */
  versions?: IPVersions;
}
/**
 * MultiUpstreams is a single dynamic upstream source that
 * aggregates the results of multiple dynamic upstream sources.
 * All configured sources will be queried in order, with their
 * results appended to the end of the list. Errors returned
 * from individual sources will be logged and the next source
 * will continue to be invoked.
 * This module makes it easy to implement redundant cluster
 * failovers, especially in conjunction with the `first` load
 * balancing policy: if the first source returns an error or
 * no upstreams, the second source's upstreams will be used
 * naturally.
 */
export interface MultiUpstreams {
  /**
   * The list of upstream source modules to get upstreams from.
   * They will be queried in order, with their results appended
   * in the order they are returned.
   */
  sources?: unknown[];
}
/**
 * UpstreamResolver holds the set of addresses of DNS resolvers of
 * upstream addresses
 */
export interface UpstreamResolver {
  /**
   * The addresses of DNS resolvers to use when looking up the addresses of proxy upstreams.
   * It accepts [network addresses](/docs/conventions#network-addresses)
   * with port range of only 1. If the host is an IP address, it will be dialed directly to resolve the upstream server.
   * If the host is not an IP address, the addresses are resolved using the [name resolution convention](https://golang.org/pkg/net/#hdr-Name_Resolution) of the Go standard library.
   * If the array contains more than 1 resolver address, one is chosen at random.
   */
  addresses?: string[];
}
